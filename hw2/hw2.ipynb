{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 2: Phoneme Classification**\n","metadata":{"id":"OYlaRwNu7ojq"}},{"cell_type":"markdown","source":"Objectives:\n* Solve a classification problem with deep neural networks (DNNs).\n* Understand recursive neural networks (RNNs).\n\nIf you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com","metadata":{"id":"A7DRC5V7_8A5"}},{"cell_type":"markdown","source":"# Some Utility Functions\n**Fixes random number generator seeds for reproducibility.**","metadata":{"id":"pADUiYODJE1O"}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport random\n\ndef same_seeds(seed):\n    random.seed(seed) \n    np.random.seed(seed)  \n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed) \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"id":"BsZKgBZQJjaE","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T14:23:26.772898Z","iopub.execute_input":"2023-03-10T14:23:26.773621Z","iopub.status.idle":"2023-03-10T14:23:29.028169Z","shell.execute_reply.started":"2023-03-10T14:23:26.773533Z","shell.execute_reply":"2023-03-10T14:23:29.026827Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n\nA phoneme may span several frames and is dependent to past and future frames. \\\nHence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n\nFeel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)","metadata":{"id":"_L_4anls8Drv"}},{"cell_type":"code","source":"import os\nimport torch\nfrom tqdm import tqdm\n\ndef load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x, n):\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\ndef concat_feat(x, concat_n):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n) \n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n\ndef preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n    class_num = 41 # NOTE: pre-computed, should not need change\n\n    if split == 'train' or split == 'val':\n        mode = 'train'\n    elif split == 'test':\n        mode = 'test'\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    label_dict = {}\n    if mode == 'train':\n        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n        \n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.seed(random_seed)\n        random.shuffle(usage_list)\n        train_len = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n\n    elif mode == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    max_len = 3000000\n    X = torch.empty(max_len, 39 * concat_nframes)\n    if mode == 'train':\n        y = torch.empty(max_len, dtype=torch.long)\n\n    idx = 0\n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        cur_len = len(feat)\n        feat = concat_feat(feat, concat_nframes)\n        if mode == 'train':\n          label = torch.LongTensor(label_dict[fname])\n\n        X[idx: idx + cur_len, :] = feat\n        if mode == 'train':\n          y[idx: idx + cur_len] = label\n\n        idx += cur_len\n\n    X = X[:idx, :]\n    if mode == 'train':\n      y = y[:idx]\n\n    print(f'[INFO] {split} set')\n    print(X.shape)\n    if mode == 'train':\n      print(y.shape)\n      return X, y\n    else:\n      return X\n","metadata":{"id":"IJjLT8em-y9G","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T14:23:29.030429Z","iopub.execute_input":"2023-03-10T14:23:29.030987Z","iopub.status.idle":"2023-03-10T14:23:29.056124Z","shell.execute_reply.started":"2023-03-10T14:23:29.030951Z","shell.execute_reply":"2023-03-10T14:23:29.055061Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"us5XW_x6udZQ"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = X\n        if y is not None:\n            self.label = torch.LongTensor(y)\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)\n","metadata":{"id":"Fjf5EcmJtf4e","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T14:23:29.058230Z","iopub.execute_input":"2023-03-10T14:23:29.058821Z","iopub.status.idle":"2023-03-10T14:23:29.071030Z","shell.execute_reply.started":"2023-03-10T14:23:29.058763Z","shell.execute_reply":"2023-03-10T14:23:29.070087Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Model\nFeel free to modify the structure of the model.","metadata":{"id":"IRqKNvNZwe3V"}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass BasicBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(BasicBlock, self).__init__()\n\n        self.block = nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.BatchNorm1d(output_dim),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n        super(Classifier, self).__init__()\n\n        self.fc = nn.Sequential(\n            BasicBlock(input_dim, hidden_dim),\n            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x","metadata":{"id":"Bg-GRd7ywdrL","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T14:23:29.075629Z","iopub.execute_input":"2023-03-10T14:23:29.078231Z","iopub.status.idle":"2023-03-10T14:23:29.087170Z","shell.execute_reply.started":"2023-03-10T14:23:29.078189Z","shell.execute_reply":"2023-03-10T14:23:29.086209Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Hyper-parameters","metadata":{"id":"TlIq8JeqvvHC"}},{"cell_type":"code","source":"# data prarameters\nconcat_nframes = 31              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.75               # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 1213                        # random seed\nbatch_size = 64                # batch size\nnum_epoch = 60                   # the number of training epoch\nlearning_rate = 1e-4         # learning rate\nmodel_path = './model.ckpt'     # the path where the checkpoint will be saved\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nhidden_layers = 4               # the number of hidden layers\nhidden_dim = 1024               # the hidden dim","metadata":{"id":"iIHn79Iav1ri","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T14:23:29.088951Z","iopub.execute_input":"2023-03-10T14:23:29.089636Z","iopub.status.idle":"2023-03-10T14:23:29.102357Z","shell.execute_reply.started":"2023-03-10T14:23:29.089600Z","shell.execute_reply":"2023-03-10T14:23:29.101272Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{"id":"IIUFRgG5yoDn"}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport gc\n\nsame_seeds(seed)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'DEVICE: {device}')\n\n# preprocess data\ntrain_X, train_y = preprocess_data(split='train', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\nval_X, val_y = preprocess_data(split='val', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n\n# get dataset\ntrain_set = LibriDataset(train_X, train_y)\nval_set = LibriDataset(val_X, val_y)\n\n# remove raw feature to save memory\ndel train_X, train_y, val_X, val_y\ngc.collect()\n\n# get dataloader\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"id":"c1zI3v5jyrDn","outputId":"6e7eeb1b-b76a-4846-b9b4-055d66c05661","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T14:23:29.103813Z","iopub.execute_input":"2023-03-10T14:23:29.104837Z","iopub.status.idle":"2023-03-10T14:24:05.631522Z","shell.execute_reply.started":"2023-03-10T14:23:29.104801Z","shell.execute_reply":"2023-03-10T14:24:05.630538Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"DEVICE: cuda\n[Dataset] - # phone classes: 41, number of utterances for train: 2571\n","output_type":"stream"},{"name":"stderr","text":"2571it [00:25, 101.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] train set\ntorch.Size([1588590, 1209])\ntorch.Size([1588590])\n[Dataset] - # phone classes: 41, number of utterances for val: 858\n","output_type":"stream"},{"name":"stderr","text":"858it [00:09, 88.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] val set\ntorch.Size([528204, 1209])\ntorch.Size([528204])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"pwWH1KIqzxEr"}},{"cell_type":"code","source":"# create model, define a loss function, and optimizer\nmodel = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\ncriterion = nn.CrossEntropyLoss() \noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\nbest_acc = 0.0\nfor epoch in range(num_epoch):\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    \n    # training\n    model.train() # set the model to training mode\n    for i, batch in enumerate(tqdm(train_loader)):\n        features, labels = batch\n        features = features.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad() \n        outputs = model(features) \n        \n        loss = criterion(outputs, labels)\n        loss.backward() \n        optimizer.step() \n        \n        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n        train_loss += loss.item()\n    \n    # validation\n    model.eval() # set the model to evaluation mode\n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(val_loader)):\n            features, labels = batch\n            features = features.to(device)\n            labels = labels.to(device)\n            outputs = model(features)\n            \n            loss = criterion(outputs, labels) \n            \n            _, val_pred = torch.max(outputs, 1) \n            val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n            val_loss += loss.item()\n\n    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n\n    # if the model improves, save a checkpoint at this epoch\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), model_path)\n        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n","metadata":{"id":"CdMWsBs7zzNs","outputId":"426e0a6c-02bd-4f59-e45c-b05e3f28965d","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T14:24:05.633286Z","iopub.execute_input":"2023-03-10T14:24:05.633972Z","iopub.status.idle":"2023-03-10T16:31:30.033901Z","shell.execute_reply.started":"2023-03-10T14:24:05.633933Z","shell.execute_reply":"2023-03-10T16:31:30.032928Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 24822/24822 [01:59<00:00, 208.18it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 803.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[001/060] Train Acc: 0.56359 Loss: 1.44087 | Val Acc: 0.65519 loss: 1.10276\nsaving model with acc 0.65519\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.38it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 790.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"[002/060] Train Acc: 0.62818 Loss: 1.19760 | Val Acc: 0.68260 loss: 1.00802\nsaving model with acc 0.68260\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:57<00:00, 211.15it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 763.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[003/060] Train Acc: 0.65122 Loss: 1.11526 | Val Acc: 0.69740 loss: 0.95655\nsaving model with acc 0.69740\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:58<00:00, 208.68it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 755.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"[004/060] Train Acc: 0.66644 Loss: 1.06288 | Val Acc: 0.70556 loss: 0.92917\nsaving model with acc 0.70556\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.40it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 750.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"[005/060] Train Acc: 0.67757 Loss: 1.02385 | Val Acc: 0.71414 loss: 0.89938\nsaving model with acc 0.71414\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.92it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 758.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"[006/060] Train Acc: 0.68624 Loss: 0.99202 | Val Acc: 0.71931 loss: 0.88056\nsaving model with acc 0.71931\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.69it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 794.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"[007/060] Train Acc: 0.69362 Loss: 0.96633 | Val Acc: 0.72343 loss: 0.86719\nsaving model with acc 0.72343\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:57<00:00, 211.90it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 792.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"[008/060] Train Acc: 0.70044 Loss: 0.94425 | Val Acc: 0.72906 loss: 0.85405\nsaving model with acc 0.72906\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.96it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 797.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"[009/060] Train Acc: 0.70515 Loss: 0.92647 | Val Acc: 0.73239 loss: 0.84210\nsaving model with acc 0.73239\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.40it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 785.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[010/060] Train Acc: 0.70984 Loss: 0.90900 | Val Acc: 0.73295 loss: 0.83807\nsaving model with acc 0.73295\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.16it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 791.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"[011/060] Train Acc: 0.71399 Loss: 0.89451 | Val Acc: 0.73464 loss: 0.83099\nsaving model with acc 0.73464\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.20it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 785.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"[012/060] Train Acc: 0.71785 Loss: 0.88140 | Val Acc: 0.73793 loss: 0.82271\nsaving model with acc 0.73793\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.07it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 785.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"[013/060] Train Acc: 0.72142 Loss: 0.86938 | Val Acc: 0.73973 loss: 0.81782\nsaving model with acc 0.73973\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.47it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 800.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"[014/060] Train Acc: 0.72502 Loss: 0.85779 | Val Acc: 0.74154 loss: 0.81072\nsaving model with acc 0.74154\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.47it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 792.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"[015/060] Train Acc: 0.72730 Loss: 0.84874 | Val Acc: 0.74231 loss: 0.80806\nsaving model with acc 0.74231\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.21it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 793.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"[016/060] Train Acc: 0.73023 Loss: 0.84004 | Val Acc: 0.74442 loss: 0.80162\nsaving model with acc 0.74442\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.11it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 792.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"[017/060] Train Acc: 0.73200 Loss: 0.83206 | Val Acc: 0.74491 loss: 0.80129\nsaving model with acc 0.74491\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.26it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 790.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"[018/060] Train Acc: 0.73465 Loss: 0.82293 | Val Acc: 0.74576 loss: 0.79830\nsaving model with acc 0.74576\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.96it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 767.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"[019/060] Train Acc: 0.73650 Loss: 0.81634 | Val Acc: 0.74664 loss: 0.79727\nsaving model with acc 0.74664\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.19it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 758.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"[020/060] Train Acc: 0.73842 Loss: 0.80991 | Val Acc: 0.74750 loss: 0.79376\nsaving model with acc 0.74750\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.94it/s]\n100%|██████████| 8254/8254 [00:11<00:00, 748.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"[021/060] Train Acc: 0.74025 Loss: 0.80353 | Val Acc: 0.74841 loss: 0.79152\nsaving model with acc 0.74841\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.73it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 756.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"[022/060] Train Acc: 0.74154 Loss: 0.79705 | Val Acc: 0.74960 loss: 0.78565\nsaving model with acc 0.74960\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:55<00:00, 214.10it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 765.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"[023/060] Train Acc: 0.74367 Loss: 0.79160 | Val Acc: 0.74921 loss: 0.78675\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:55<00:00, 214.04it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 789.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"[024/060] Train Acc: 0.74522 Loss: 0.78690 | Val Acc: 0.75059 loss: 0.78339\nsaving model with acc 0.75059\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.69it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 781.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"[025/060] Train Acc: 0.74661 Loss: 0.78177 | Val Acc: 0.75118 loss: 0.78237\nsaving model with acc 0.75118\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.22it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 792.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[026/060] Train Acc: 0.74716 Loss: 0.77728 | Val Acc: 0.75087 loss: 0.78443\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.27it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 783.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[027/060] Train Acc: 0.74873 Loss: 0.77343 | Val Acc: 0.75149 loss: 0.78049\nsaving model with acc 0.75149\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:58<00:00, 208.82it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 784.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"[028/060] Train Acc: 0.75043 Loss: 0.76806 | Val Acc: 0.75183 loss: 0.78044\nsaving model with acc 0.75183\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:57<00:00, 211.86it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 792.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"[029/060] Train Acc: 0.75134 Loss: 0.76437 | Val Acc: 0.75309 loss: 0.77743\nsaving model with acc 0.75309\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:57<00:00, 212.13it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 796.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"[030/060] Train Acc: 0.75231 Loss: 0.76114 | Val Acc: 0.75266 loss: 0.77724\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.14it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 795.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"[031/060] Train Acc: 0.75382 Loss: 0.75699 | Val Acc: 0.75355 loss: 0.77699\nsaving model with acc 0.75355\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.85it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 791.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"[032/060] Train Acc: 0.75465 Loss: 0.75266 | Val Acc: 0.75333 loss: 0.77719\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.07it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 792.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"[033/060] Train Acc: 0.75573 Loss: 0.74969 | Val Acc: 0.75333 loss: 0.77562\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.91it/s]\n100%|██████████| 8254/8254 [00:11<00:00, 749.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"[034/060] Train Acc: 0.75610 Loss: 0.74722 | Val Acc: 0.75420 loss: 0.77543\nsaving model with acc 0.75420\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.46it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 767.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"[035/060] Train Acc: 0.75716 Loss: 0.74365 | Val Acc: 0.75502 loss: 0.77397\nsaving model with acc 0.75502\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.14it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 767.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"[036/060] Train Acc: 0.75792 Loss: 0.74080 | Val Acc: 0.75506 loss: 0.77329\nsaving model with acc 0.75506\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:55<00:00, 214.15it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 768.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"[037/060] Train Acc: 0.75882 Loss: 0.73801 | Val Acc: 0.75567 loss: 0.77004\nsaving model with acc 0.75567\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.00it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 764.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"[038/060] Train Acc: 0.75944 Loss: 0.73615 | Val Acc: 0.75577 loss: 0.76997\nsaving model with acc 0.75577\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.83it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 765.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"[039/060] Train Acc: 0.76031 Loss: 0.73279 | Val Acc: 0.75616 loss: 0.77076\nsaving model with acc 0.75616\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.38it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 789.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"[040/060] Train Acc: 0.76115 Loss: 0.72920 | Val Acc: 0.75584 loss: 0.76911\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.97it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 785.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"[041/060] Train Acc: 0.76246 Loss: 0.72643 | Val Acc: 0.75658 loss: 0.77062\nsaving model with acc 0.75658\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.23it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 794.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"[042/060] Train Acc: 0.76265 Loss: 0.72493 | Val Acc: 0.75547 loss: 0.76853\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.91it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 795.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[043/060] Train Acc: 0.76292 Loss: 0.72202 | Val Acc: 0.75636 loss: 0.76875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.59it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 795.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"[044/060] Train Acc: 0.76414 Loss: 0.71974 | Val Acc: 0.75616 loss: 0.76996\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.47it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 789.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"[045/060] Train Acc: 0.76473 Loss: 0.71740 | Val Acc: 0.75712 loss: 0.76646\nsaving model with acc 0.75712\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.61it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 785.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[046/060] Train Acc: 0.76469 Loss: 0.71592 | Val Acc: 0.75789 loss: 0.76319\nsaving model with acc 0.75789\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:55<00:00, 214.15it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 788.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"[047/060] Train Acc: 0.76585 Loss: 0.71335 | Val Acc: 0.75702 loss: 0.76548\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:57<00:00, 212.00it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 792.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"[048/060] Train Acc: 0.76640 Loss: 0.71102 | Val Acc: 0.75740 loss: 0.76488\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.86it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 785.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"[049/060] Train Acc: 0.76716 Loss: 0.70872 | Val Acc: 0.75844 loss: 0.76569\nsaving model with acc 0.75844\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.43it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 787.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"[050/060] Train Acc: 0.76752 Loss: 0.70723 | Val Acc: 0.75798 loss: 0.76405\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.33it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 759.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"[051/060] Train Acc: 0.76873 Loss: 0.70467 | Val Acc: 0.75776 loss: 0.76448\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:58<00:00, 208.90it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 759.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"[052/060] Train Acc: 0.76877 Loss: 0.70310 | Val Acc: 0.75798 loss: 0.76498\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.14it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 761.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"[053/060] Train Acc: 0.76861 Loss: 0.70183 | Val Acc: 0.75869 loss: 0.76210\nsaving model with acc 0.75869\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:57<00:00, 211.93it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 756.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"[054/060] Train Acc: 0.76994 Loss: 0.70053 | Val Acc: 0.75861 loss: 0.76381\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.62it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 787.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"[055/060] Train Acc: 0.76969 Loss: 0.69990 | Val Acc: 0.75869 loss: 0.76316\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 213.01it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 801.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"[056/060] Train Acc: 0.77103 Loss: 0.69671 | Val Acc: 0.75786 loss: 0.76673\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:57<00:00, 211.90it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 792.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"[057/060] Train Acc: 0.77115 Loss: 0.69530 | Val Acc: 0.75926 loss: 0.76183\nsaving model with acc 0.75926\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.98it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 790.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"[058/060] Train Acc: 0.77169 Loss: 0.69339 | Val Acc: 0.75851 loss: 0.76159\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:57<00:00, 211.91it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 790.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"[059/060] Train Acc: 0.77281 Loss: 0.69057 | Val Acc: 0.75927 loss: 0.76135\nsaving model with acc 0.75927\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 24822/24822 [01:56<00:00, 212.47it/s]\n100%|██████████| 8254/8254 [00:10<00:00, 787.93it/s]","output_type":"stream"},{"name":"stdout","text":"[060/060] Train Acc: 0.77325 Loss: 0.68903 | Val Acc: 0.75915 loss: 0.76164\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_set, val_set\ndel train_loader, val_loader\ngc.collect()","metadata":{"id":"ab33MxosWLmG","outputId":"0d5e2cc6-46f3-41b9-ea09-79fdf660898f","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T16:31:30.035329Z","iopub.execute_input":"2023-03-10T16:31:30.036518Z","iopub.status.idle":"2023-03-10T16:31:30.698161Z","shell.execute_reply.started":"2023-03-10T16:31:30.036476Z","shell.execute_reply":"2023-03-10T16:31:30.697202Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"markdown","source":"# Testing\nCreate a testing dataset, and load model from the saved checkpoint.","metadata":{"id":"1Hi7jTn3PX-m"}},{"cell_type":"code","source":"# load data\ntest_X = preprocess_data(split='test', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes)\ntest_set = LibriDataset(test_X, None)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)","metadata":{"id":"VOG1Ou0PGrhc","outputId":"3373d328-bb42-48ec-92f2-e2e935c3344c","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T16:31:30.699552Z","iopub.execute_input":"2023-03-10T16:31:30.700473Z","iopub.status.idle":"2023-03-10T16:32:14.722216Z","shell.execute_reply.started":"2023-03-10T16:31:30.700428Z","shell.execute_reply":"2023-03-10T16:32:14.721245Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[Dataset] - # phone classes: 41, number of utterances for test: 857\n","output_type":"stream"},{"name":"stderr","text":"857it [00:43, 19.48it/s]","output_type":"stream"},{"name":"stdout","text":"[INFO] test set\ntorch.Size([527364, 1209])\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# load model\nmodel = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\nmodel.load_state_dict(torch.load(model_path))","metadata":{"id":"ay0Fu8Ovkdad","outputId":"fe130106-a997-4985-fc4b-5102414afe31","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T16:32:14.725494Z","iopub.execute_input":"2023-03-10T16:32:14.726314Z","iopub.status.idle":"2023-03-10T16:32:14.801295Z","shell.execute_reply.started":"2023-03-10T16:32:14.726274Z","shell.execute_reply":"2023-03-10T16:32:14.800174Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"Make prediction.","metadata":{"id":"zp-DV1p4r7Nz"}},{"cell_type":"code","source":"pred = np.array([], dtype=np.int32)\n\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(test_loader)):\n        features = batch\n        features = features.to(device)\n\n        outputs = model(features)\n\n        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n","metadata":{"id":"84HU5GGjPqR0","outputId":"b49ffee0-1785-419d-e56c-0ddd734b2c99","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T16:32:14.802676Z","iopub.execute_input":"2023-03-10T16:32:14.803134Z","iopub.status.idle":"2023-03-10T16:32:24.600228Z","shell.execute_reply.started":"2023-03-10T16:32:14.803100Z","shell.execute_reply":"2023-03-10T16:32:24.599287Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 8241/8241 [00:09<00:00, 842.07it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Write prediction to a CSV file.\n\nAfter finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle.","metadata":{"id":"wyZqy40Prz0v"}},{"cell_type":"code","source":"with open('prediction.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"id":"GuljYSPHcZir","vscode":{"languageId":"python"},"execution":{"iopub.status.busy":"2023-03-10T16:32:24.601767Z","iopub.execute_input":"2023-03-10T16:32:24.602430Z","iopub.status.idle":"2023-03-10T16:32:25.003150Z","shell.execute_reply.started":"2023-03-10T16:32:24.602391Z","shell.execute_reply":"2023-03-10T16:32:25.002183Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'prediction.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-10T16:32:25.004639Z","iopub.execute_input":"2023-03-10T16:32:25.005019Z","iopub.status.idle":"2023-03-10T16:32:25.012543Z","shell.execute_reply.started":"2023-03-10T16:32:25.004983Z","shell.execute_reply":"2023-03-10T16:32:25.011284Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/prediction.csv","text/html":"<a href='prediction.csv' target='_blank'>prediction.csv</a><br>"},"metadata":{}}]}]}